{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ba54bdf",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'pandas' has no attribute 'core' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_433366/1326618361.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# !pip install bs4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# !pip install xgboost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dhdsblend2021/lib/python3.8/site-packages/pandas/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tester\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dhdsblend2021/lib/python3.8/site-packages/pandas/testing.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \"\"\"\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m from pandas._testing import (\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0massert_extension_array_equal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0massert_frame_equal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dhdsblend2021/lib/python3.8/site-packages/pandas/_testing.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m   2904\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2905\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2906\u001b[0;31m \u001b[0mcython_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSelectionMixin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cython_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2907\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: partially initialized module 'pandas' has no attribute 'core' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "# !pip install selenium\n",
    "# !pip install webdriver-manager\n",
    "# !pip install bs4\n",
    "# !pip install xgboost\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import RegexpTokenizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import LancasterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from os import path\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "import seaborn as sns\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "import requests\n",
    "import warnings\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88f56b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_true_location_eliel = '~/Downloads/DHDS/TP Final/git_fake_news/data/True.csv'\n",
    "data_fake_location_eliel = '~/Downloads/DHDS/TP Final/git_fake_news/data/Fake.csv'\n",
    "# data_true_location_lucas = 'C:\\\\Users\\\\Lucas Choconi\\\\Documents\\\\DH\\\\Datasets\\\\fakenews\\True.csv'\n",
    "# data_fake_location_lucas = 'C:\\\\Users\\\\Lucas Choconi\\\\Documents\\\\DH\\\\Datasets\\\\fakenews\\Fake.csv'\n",
    "# data_true_location_ger = ''\n",
    "# data_fake_location_ger =  ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d24083b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file_names_true = pd.read_csv(data_true_location_eliel)\n",
    "file_names_true['real'] = 'True'\n",
    "file_names_fake = pd.read_csv(data_fake_location_eliel)\n",
    "file_names_fake['real'] = 'Fake'\n",
    "data = file_names_fake.append(file_names_true, ignore_index=True)\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d981ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d23e349",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test = train_test_split(data, test_size=0.2)\n",
    "sample_size = 5000\n",
    "data_train = data_train.sample(sample_size)\n",
    "data_test = data_test.sample(sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519d9054",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_en = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2254ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_stopword_filtering(stopwords_en): \n",
    "    stopwords_en.append('reuter')\n",
    "    stopwords_en.append('said')\n",
    "    stopwords_en.append('Reuters')\n",
    "    stopwords_en.append('via')\n",
    "    stopwords_en.append('imag')\n",
    "    stopwords_en.append('https')\n",
    "    stopwords_en.append('com')\n",
    "    stopwords_en.append('one')\n",
    "    stopwords_en.append('u')\n",
    "    stopwords_en.append('also')\n",
    "    stopwords_en.append('would')\n",
    "    stopwords_en.append('featur')\n",
    "    stopwords_en.append('pic')\n",
    "    stopwords_en.append('us')\n",
    "    stopwords_en.append('wednesday')\n",
    "    stopwords_en.append('friday')\n",
    "    stopwords_en.append('monday')\n",
    "    stopwords_en.append('tuesday')\n",
    "    stopwords_en.append('saturday')\n",
    "    stopwords_en.append('sunday')\n",
    "    stopwords_en.append('thursday')\n",
    "    stopwords_en.append('getti')\n",
    "    stopwords_en.append('read')\n",
    "    stopwords_en.append('gop')\n",
    "    stopwords_en.append('watch')\n",
    "    stopwords_en.append('donald')\n",
    "    stopwords_en.append('trump')\n",
    "    stopwords_en.append('hillari')\n",
    "    stopwords_en.append('mr')\n",
    "    stopwords_en.append('accord')\n",
    "    stopwords_en.append('america')\n",
    "    stopwords_en.append('seem')\n",
    "    stopwords_en.append('youtub')\n",
    "    stopwords_en.append('21st')\n",
    "    return stopwords_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196a7382",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_en_filtered = manual_stopword_filtering(stopwords_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f98208",
   "metadata": {},
   "outputs": [],
   "source": [
    "porter = PorterStemmer()\n",
    "lancaster= LancasterStemmer()\n",
    "\n",
    "stopwords_en_porter = [porter.stem(x) for x in stopwords_en]\n",
    "stopwords_en_lancaster = [lancaster.stem(x) for x in stopwords_en]\n",
    "stopwords_en_filtered_poter = [porter.stem(x) for x in stopwords_en_filtered]\n",
    "stopwords_en_filtered_lancaster = [lancaster.stem(x) for x in stopwords_en_filtered]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3bfa21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def porter_tokenizer(text):\n",
    "    words = word_tokenize(text) # tokenize\n",
    "    porter = PorterStemmer()\n",
    "    stemmed_words=[porter.stem(word) for word in words]  # obtain stem words\n",
    "    return stemmed_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f51b2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer=CountVectorizer(stop_words = stopwords_en, lowecase = true, strip_accents='unicode', tokenizer = porter_tokenizer);\n",
    "vectorizer.fit(data_train['text'])\n",
    "vectorizer_matrix = vectorizer.transform(data_train['text'])\n",
    "pd.DataFrame(vectorizer_matrix.todense(), columns=vectorizer.get_feature_names()).head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c92cff1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0bf787",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd805c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_en = stopwords.words('english')\n",
    "\n",
    "d = path.dirname(__file__) if \"__file__\" in locals() else os.getcwd()\n",
    "mask_pos = np.array(Image.open(path.join(d, \"Thumbs.png\")))\n",
    "mask_neg = np.array(Image.open(path.join(d, \"Thumbsdw.png\")))\n",
    "\n",
    "text_fake = \" \".join(text for text in file_names[file_names['real']=='Fake'].text)\n",
    "text_true = \" \".join(text for text in file_names[file_names['real']=='True'].text)\n",
    "\n",
    "wordcloud_fake = WordCloud(stopwords=stopwords_en,  mask=mask_neg, max_words=500, background_color=\"white\").generate(text_fake)\n",
    "wordcloud_true = WordCloud(stopwords=stopwords_en, mask=mask_pos, max_words=500, background_color=\"white\").generate(text_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966e661b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def blue_color_func(word, font_size, position,orientation,random_state=None, **kwargs):\n",
    "    blues = \"hsl(215,100%%, %d%%)\" % np.random.choice(np.arange(25, 65, 5, dtype=int))\n",
    "    reds = \"hsl(0,100%%, %d%%)\" % np.random.choice(np.arange(40, 80, 5, dtype=int))\n",
    "    choice = np.random.choice([0, 1])\n",
    "    if choice == 0:\n",
    "        return blues\n",
    "    else:\n",
    "        return reds\n",
    "\n",
    "fig, axs = plt.subplots(1, 2,figsize=(20,10))  \n",
    "\n",
    "axs[1].imshow(wordcloud_fake.recolor(color_func=blue_color_func),interpolation=\"bilinear\")\n",
    "axs[1].axis(\"off\")\n",
    "axs[1].title.set_text('FAKE')\n",
    "axs[0].imshow(wordcloud_true.recolor(color_func=blue_color_func),interpolation=\"bilinear\")\n",
    "axs[0].axis(\"off\")\n",
    "axs[0].title.set_text('TRUE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38416dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_review(review_text, tokenizer, stemmer, stopwords):    \n",
    "    \n",
    "    #tokens (eliminamos todos los signos de puntuación)\n",
    "    words = tokenizer.tokenize(review_text)\n",
    "    \n",
    "    # stemming: raiz y minúsculas:\n",
    "    stem_words = [stemmer.stem(x) for x in words]\n",
    "    \n",
    "    # eliminamos stopwords (ya pasaron por stem)\n",
    "    clean_words = [x for x in stem_words if x not in stopwords]\n",
    "    \n",
    "    result = \" \".join(clean_words)\n",
    "    \n",
    "    return(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6533980d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r\"\\w+\")\n",
    "englishStemmer = SnowballStemmer(\"english\")\n",
    "stopwords_en = stopwords.words('english')\n",
    "stopwords_en.append('reuter')\n",
    "stopwords_en.append('said')\n",
    "stopwords_en.append('Reuters')\n",
    "stopwords_en.append('via')\n",
    "stopwords_en.append('imag')\n",
    "stopwords_en.append('https')\n",
    "stopwords_en.append('com')\n",
    "stopwords_en.append('one')\n",
    "stopwords_en.append('u')\n",
    "stopwords_en.append('also')\n",
    "stopwords_en.append('would')\n",
    "stopwords_en.append('featur')\n",
    "stopwords_en.append('pic')\n",
    "stopwords_en.append('us')\n",
    "stopwords_en.append('wednesday')\n",
    "stopwords_en.append('friday')\n",
    "stopwords_en.append('monday')\n",
    "stopwords_en.append('tuesday')\n",
    "stopwords_en.append('saturday')\n",
    "stopwords_en.append('sunday')\n",
    "stopwords_en.append('thursday')\n",
    "stopwords_en.append('getti')\n",
    "stopwords_en.append('read')\n",
    "stopwords_en.append('gop')\n",
    "stopwords_en.append('watch')\n",
    "stopwords_en.append('donald')\n",
    "stopwords_en.append('trump')\n",
    "stopwords_en.append('hillari')\n",
    "stopwords_en.append('mr')\n",
    "stopwords_en.append('accord')\n",
    "stopwords_en.append('america')\n",
    "stopwords_en.append('seem')\n",
    "stopwords_en.append('youtub')\n",
    "stopwords_en.append('21st')\n",
    "stopwords_en_stem = [englishStemmer.stem(x) for x in stopwords_en]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8980cdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "\n",
    "clean_train = data_train.text.progress_apply(lambda x: clean_review(x, tokenizer, englishStemmer, stopwords_en_stem))\n",
    "clean_test = data_test.text.progress_apply(lambda x: clean_review(x, tokenizer, englishStemmer, stopwords_en_stem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ab4282",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer()\n",
    "count_vectorizer.fit(clean_train)\n",
    "X_train_sparse = count_vectorizer.transform(clean_train)\n",
    "X_test_sparse = count_vectorizer.transform(clean_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997a04d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(X_train_sparse.todense(), \n",
    "             columns = count_vectorizer.get_feature_names()) \n",
    "y_train = data_train.real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80076db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.DataFrame(X_test_sparse.todense(), \n",
    "             columns = count_vectorizer.get_feature_names()) \n",
    "y_test = data_test.real"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caba22f7",
   "metadata": {},
   "source": [
    "#### Modelo de Reg. Logistica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f66c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_model = LogisticRegression(C = 0.05, solver=\"newton-cg\", penalty=\"l2\")\n",
    "reg_model.fit(X_train, y_train)\n",
    "reg_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd5db5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "myColors = ((0.90, 0.96, 1, 1), (0.70, 0.87, 1, 1), (0, 0.40, 0.75, 0.88))\n",
    "cmap = LinearSegmentedColormap.from_list('Custom', myColors,10)\n",
    "cm = confusion_matrix(y_test, reg_model.predict(X_test))\n",
    "axis_labels = np.sort(y_test.unique())\n",
    "sns.heatmap(cm, xticklabels=axis_labels, yticklabels=axis_labels, cbar=False, annot=True, cmap=cmap, fmt='g')\n",
    "plt.ylabel('Etiquetas reales')\n",
    "plt.xlabel('Etiquetas predichas');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1134e412",
   "metadata": {},
   "outputs": [],
   "source": [
    "Coef_reg_model = pd.DataFrame(np.transpose(reg_model.coef_), index=X_train.columns, columns=['Coef'])\n",
    "Coef_reg_model['coef_abs'] = abs(Coef_reg_model['Coef'])\n",
    "Coef_reg_model = Coef_reg_model.reset_index(-1)\n",
    "Coef_reg_model['words'] = Coef_reg_model['index'] \n",
    "Coef_reg_model['freq'] = (round(Coef_reg_model['coef_abs'] / Coef_reg_model.coef_abs.sum() * Coef_reg_model.shape[0] * 1000 , 0)).apply(lambda x: int(x))\n",
    "Coef_reg_model['odds_direction'] = Coef_reg_model['Coef'].apply(lambda x: 'Negative' if x<0 else 'Positive')\n",
    "Coef_reg_model_positive = Coef_reg_model[Coef_reg_model['odds_direction']=='Positive']\n",
    "Coef_reg_model_positive = Coef_reg_model_positive.drop(['Coef' ,'coef_abs', 'index', 'odds_direction'], axis=1)\n",
    "Coef_reg_model_negative = Coef_reg_model[Coef_reg_model['odds_direction']=='Negative']\n",
    "Coef_reg_model_negative = Coef_reg_model_negative.drop(['Coef' ,'coef_abs', 'index', 'odds_direction'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d48e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuples_pos = Coef_reg_model_positive.set_index('words').T.to_dict('index')\n",
    "tuples_neg = Coef_reg_model_negative.set_index('words').T.to_dict('index')\n",
    "\n",
    "d = path.dirname(__file__) if \"__file__\" in locals() else os.getcwd()\n",
    "mask_pos = np.array(Image.open(path.join(d, \"Thumbs.png\")))\n",
    "mask_neg = np.array(Image.open(path.join(d, \"Thumbsdw.png\")))\n",
    "\n",
    "wordcloud_positive = WordCloud(max_words=500, mask=mask_pos, background_color=\"white\").generate_from_frequencies(dict(tuples_pos['freq']))\n",
    "wordcloud_negative = WordCloud(max_words=500, mask=mask_neg,background_color=\"white\").generate_from_frequencies(dict(tuples_neg['freq']))\n",
    "\n",
    "fig, axs = plt.subplots(1, 2,figsize=(20,10))\n",
    "# Display the generated image:\n",
    "axs[0].imshow(wordcloud_positive.recolor(color_func=blue_color_func, random_state=3),interpolation=\"bilinear\")\n",
    "axs[0].axis(\"off\")\n",
    "axs[0].title.set_text('Positive')\n",
    "axs[1].imshow(wordcloud_negative.recolor(color_func=blue_color_func, random_state=3),interpolation=\"bilinear\")\n",
    "axs[1].axis(\"off\")\n",
    "axs[1].title.set_text('Negative')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57141e8a",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a76c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_model = MultinomialNB()\n",
    "NB_model.fit(X_train, y_train)\n",
    "NB_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ced1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, NB_model.predict(X_test))\n",
    "sns.heatmap(cm, xticklabels=axis_labels, yticklabels=axis_labels, cbar=False, annot=True, cmap=cmap, fmt='g')\n",
    "plt.ylabel('Etiquetas reales')\n",
    "plt.xlabel('Etiquetas predichas');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749de777",
   "metadata": {},
   "source": [
    "## Modelo de Reg. Logistica Truncando palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c60537",
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components = 200);\n",
    "\n",
    "X_train_svd = svd.fit_transform(X_train)\n",
    "X_test_svd = svd.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e00a74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(svd.explained_variance_ratio_.sum())\n",
    "svd.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b86bcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_model_svd = LogisticRegression(C = 0.05, solver=\"newton-cg\", penalty=\"l2\")\n",
    "reg_model_svd.fit(X_train_svd, y_train)\n",
    "reg_model_svd.score(X_test_svd, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e689984d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, reg_model_svd.predict(X_test_svd))\n",
    "sns.heatmap(cm, xticklabels=axis_labels, yticklabels=axis_labels, cbar=False, annot=True, cmap=cmap, fmt='g')\n",
    "plt.ylabel('Etiquetas reales')\n",
    "plt.xlabel('Etiquetas predichas');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3531080",
   "metadata": {},
   "source": [
    "## Modelo de Reg. Logistica con conjunto de palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba67db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer_bigram = CountVectorizer(ngram_range = (1, 2))\n",
    "count_vectorizer_bigram.fit(clean_train)\n",
    "X_train_bigram_sparse = count_vectorizer_bigram.transform(clean_train)\n",
    "X_test_bigram_sparse = count_vectorizer_bigram.transform(clean_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e28944",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_model_bigram = LogisticRegression(C = 0.05, solver=\"newton-cg\", penalty=\"l2\")\n",
    "reg_model_bigram.fit(X_train_bigram_sparse, y_train)\n",
    "reg_model_bigram.score(X_test_bigram_sparse, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03175d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, reg_model_bigram.predict(X_test_bigram_sparse))\n",
    "sns.heatmap(cm, xticklabels=axis_labels, yticklabels=axis_labels, cbar=False, annot=True, cmap=cmap, fmt='g')\n",
    "plt.ylabel('Etiquetas reales')\n",
    "plt.xlabel('Etiquetas predichas');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0010f7fa",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ebede9",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tree = tree.DecisionTreeClassifier(criterion='entropy', max_depth=4)\n",
    "my_tree.fit(X_train, y_train)\n",
    "my_tree.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db62cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, my_tree.predict(X_test))\n",
    "sns.heatmap(cm, xticklabels=axis_labels, yticklabels=axis_labels, cbar=False, annot=True, cmap=cmap, fmt='g')\n",
    "plt.ylabel('Etiquetas reales')\n",
    "plt.xlabel('Etiquetas predichas');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1e503e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,6))\n",
    "tree.plot_tree(my_tree,feature_names = X_train.columns,filled=True,rounded=True, fontsize = 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908a836b",
   "metadata": {},
   "source": [
    "## Random Decision Tree Classifier and Extra random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a1359c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''random_forest = RandomForestClassifier(n_estimators=100, \n",
    "                                      criterion='gini', \n",
    "                                      max_depth = 4, \n",
    "                                      bootstrap=True, \n",
    "                                      n_jobs = -1, \n",
    "                                      random_state = 127,\n",
    "                                      max_samples= 0.3)\n",
    "random_forest.fit(X_train, y_train)\n",
    "random_forest.score(X_test, y_test)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a530ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''cm = confusion_matrix(y_test, random_forest.predict(X_test))\n",
    "sns.heatmap(cm, xticklabels=axis_labels, yticklabels=axis_labels, cbar=False, annot=True, cmap=cmap, fmt='g')\n",
    "plt.ylabel('Etiquetas reales')\n",
    "plt.xlabel('Etiquetas predichas');'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab396e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''extra_random_forest = ExtraTreesClassifier(n_estimators=100, \n",
    "                                      criterion='gini', \n",
    "                                      max_depth = 4, \n",
    "                                      bootstrap=True, \n",
    "                                      n_jobs = -1, \n",
    "                                      random_state = 127,\n",
    "                                      max_samples= 0.3)\n",
    "extra_random_forest.fit(X_train, y_train)\n",
    "extra_random_forest.score(X_test, y_test)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce83de6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''cm = confusion_matrix(y_test, extra_random_forest.predict(X_test))\n",
    "sns.heatmap(cm, xticklabels=axis_labels, yticklabels=axis_labels, cbar=False, annot=True, cmap=cmap, fmt='g')\n",
    "plt.ylabel('Etiquetas reales')\n",
    "plt.xlabel('Etiquetas predichas');'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1cbc2b",
   "metadata": {},
   "source": [
    "## Boosting de Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34901454",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''base_classifier = ExtraTreesClassifier(n_estimators=100, \n",
    "                                      criterion='gini', \n",
    "                                      max_depth = 4, \n",
    "                                      bootstrap=True, \n",
    "                                      n_jobs = -1, \n",
    "                                      random_state = 127,\n",
    "                                      max_samples= 0.3)\n",
    "\n",
    "boost_tree = AdaBoostClassifier(base_estimator = base_classifier, \n",
    "                            n_estimators = 200,\n",
    "                            learning_rate = 0.8,                                       \n",
    "                            random_state = 127)\n",
    "boost_tree.fit(X_train, y_train) \n",
    "boost_tree.score(X_test, y_test)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b9586a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''cm = confusion_matrix(y_test, boost_tree.predict(X_test))\n",
    "sns.heatmap(cm, xticklabels=axis_labels, yticklabels=axis_labels, cbar=False, annot=True, cmap=cmap, fmt='g')\n",
    "plt.ylabel('Etiquetas reales')\n",
    "plt.xlabel('Etiquetas predichas');'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe29d9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''gb_classifier = GradientBoostingClassifier(loss = 'deviance',\n",
    "                                           learning_rate=0.6,\n",
    "                                           n_estimators = 200,\n",
    "                                           subsample=1,\n",
    "                                           criterion='mse',\n",
    "                                           random_state = 127)\n",
    "\n",
    "gb_classifier.fit(X_train, y_train)\n",
    "gb_classifier.score(X_test, y_test)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b5705d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''cm = confusion_matrix(y_test, gb_classifier.predict(X_test))\n",
    "sns.heatmap(cm, xticklabels=axis_labels, yticklabels=axis_labels, cbar=False, annot=True, cmap=cmap, fmt='g')\n",
    "plt.ylabel('Etiquetas reales')\n",
    "plt.xlabel('Etiquetas predichas');'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f397c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''y_train_xg = y_train.apply(lambda x: 1 if x=='Fake' else 0)\n",
    "y_test_xg = y_test.apply(lambda x: 1 if x=='Fake' else 0)\n",
    "model_xg = XGBClassifier(n_jobs=-1, use_label_encoder=False, n_estimators= 100, max_depth=4, learning_rate= 0.05)\n",
    "model_xg.fit(X_train,y_train_xg)\n",
    "model_xg.score(X_test, y_test_xg)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53da0c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''cm = confusion_matrix(y_test_xg, model_xg.predict(X_test))\n",
    "sns.heatmap(cm, xticklabels=axis_labels, yticklabels=axis_labels, cbar=False, annot=True, cmap=cmap, fmt='g')\n",
    "plt.ylabel('Etiquetas reales')\n",
    "plt.xlabel('Etiquetas predichas');'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7f1402",
   "metadata": {},
   "source": [
    "## A traves de webscraping se buscan noticias para obtener más datos de testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12dde34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument('--headless')\n",
    "chrome_options.add_argument('--no-sandbox')\n",
    "chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "wd = webdriver.Chrome(service=Service(ChromeDriverManager().install()),options=chrome_options)\n",
    "\n",
    "def get_text_from_url_bbc(url):\n",
    "    wd.get(url)\n",
    "\n",
    "    time.sleep(1)\n",
    "\n",
    "    soup = BeautifulSoup(wd.page_source)\n",
    "    text = soup.find_all('div', {'data-component': 'text-block'}) #(?P<text>\\>(.*?)\\<)\n",
    "    text = reversed(text) \n",
    "    text2 = \"\"\n",
    "    for i in text:\n",
    "        try:\n",
    "            text2 = i.text+text2\n",
    "        except:\n",
    "            text2 = \"\"+text2\n",
    "    return text2    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46b9567",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "#https://newsapi.org/docs\n",
    "response = requests.get(\"https://newsapi.org/v2/top-headlines?sources=bbc-news&apiKey=1f83e742c8804de0a5d427510829f79b\")\n",
    "\n",
    "list_urls = []\n",
    "for i in range(0,len(response.json()['articles'])):\n",
    "    list_urls.append(response.json()['articles'][i]['url'])  \n",
    "    \n",
    "list_texts = []\n",
    "for i in range(0,len(list_urls)):\n",
    "    list_texts.append(get_text_from_url_bbc(list_urls[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5471a944",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_texts_text = pd.DataFrame(list_texts, columns=['text'])\n",
    "data_texts_text['len'] = data_texts_text.text.apply(lambda x: len(x))\n",
    "data_texts_text['real'] = 'True'\n",
    "data_texts_text = data_texts_text[data_texts_text.len>0]\n",
    "clean_texts_test = data_texts_text.text.progress_apply(lambda x: clean_review(x, tokenizer, englishStemmer, stopwords_en_stem))\n",
    "\n",
    "X_test_sparse_texts = count_vectorizer.transform(clean_texts_test)\n",
    "X_test_texts = pd.DataFrame(X_test_sparse_texts.todense(), \n",
    "             columns = count_vectorizer.get_feature_names()) \n",
    "X_test_svd_texts = svd.transform(X_test_texts)\n",
    "X_test_bigram_sparse_texts = count_vectorizer_bigram.transform(clean_texts_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0731cbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_texts_text['predict_reg_base'] = reg_model.predict(X_test_texts)\n",
    "data_texts_text['predict_prob_reg_base'] = reg_model.predict_proba(X_test_texts).T[0]\n",
    "\n",
    "data_texts_text['predict_svd'] = reg_model_svd.predict(X_test_svd_texts)\n",
    "data_texts_text['predict_prob_svd'] = reg_model_svd.predict_proba(X_test_svd_texts).T[0]\n",
    "\n",
    "data_texts_text['predict_bigram'] = reg_model_bigram.predict(X_test_bigram_sparse_texts)\n",
    "data_texts_text['predict_prob_bigram'] = reg_model_bigram.predict_proba(X_test_bigram_sparse_texts).T[0]\n",
    "\n",
    "data_texts_text['predict_my_tree'] = my_tree.predict(X_test_texts)\n",
    "data_texts_text['predict_prob_my_tree'] = my_tree.predict_proba(X_test_texts).T[0]\n",
    "\n",
    "data_texts_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cfe597",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_explainer = np.array(X_train)\n",
    "explainer = LimeTabularExplainer(X_train_explainer, \n",
    "                                 mode = \"classification\",\n",
    "                                 training_labels = y_train,\n",
    "                                 feature_names = X_train.columns,\n",
    "                                 discretize_continuous=False)\n",
    "\n",
    "#i = 13\n",
    "#data_row = np.array(X_test.iloc[i])\n",
    "data_row = np.array(X_test_texts.iloc[4])\n",
    "explanation = explainer.explain_instance(data_row, reg_model.predict_proba, num_features=10)\n",
    "explanation.as_pyplot_figure();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca96728",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_texts_text.text.iloc[4]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dhdsblend2021] *",
   "language": "python",
   "name": "conda-env-dhdsblend2021-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
